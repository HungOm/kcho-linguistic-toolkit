#!/usr/bin/env python3
"""
K'Cho Research Data Analyzer

This script analyzes and presents the research data generated by the enhanced KchoSystem.
"""

import json
from pathlib import Path
from collections import Counter

def analyze_research_data():
    """Analyze the generated research data"""
    
    print("ğŸ“Š K'CHO RESEARCH DATA ANALYSIS")
    print("=" * 60)
    
    # Find the most recent research files
    research_dir = Path("research")
    research_files = list(research_dir.glob("*_20251025_144617.json"))
    bible_files = list(research_dir.glob("*_20251025_144618.json"))
    
    if not research_files:
        print("âŒ No research files found")
        return
    
    print(f"ğŸ“ Found {len(research_files)} research files")
    print(f"ğŸ“– Found {len(bible_files)} Bible analysis files")
    
    # Analyze summary report
    summary_file = research_dir / "research_summary_20251025_144617.json"
    if summary_file.exists():
        print("\nğŸ“‹ RESEARCH SUMMARY ANALYSIS")
        print("-" * 40)
        
        with open(summary_file, 'r', encoding='utf-8') as f:
            summary = json.load(f)
        
        print(f"ğŸ•’ Generated: {summary['generation_timestamp']}")
        print(f"ğŸ“š Corpus: {summary['corpus_info']['total_sentences']} sentences")
        print(f"ğŸ§  Knowledge base: {summary['knowledge_base_stats']['total_words']} words")
        print(f"ğŸ” Gold standards: {summary['knowledge_base_stats']['gold_standard_patterns']} patterns")
        print(f"ğŸ†• Discovered: {summary['key_findings']['total_discovered_patterns']} novel patterns")
        print(f"ğŸ“ˆ Measures: {', '.join(summary['key_findings']['top_collocation_measures'])}")
    
    # Analyze discovered patterns
    patterns_file = research_dir / "discovered_patterns_20251025_144617.json"
    if patterns_file.exists():
        print("\nğŸ” DISCOVERED PATTERNS ANALYSIS")
        print("-" * 40)
        
        with open(patterns_file, 'r', encoding='utf-8') as f:
            patterns = json.load(f)
        
        print(f"ğŸ“Š Total discovered patterns: {len(patterns)}")
        
        # Analyze pattern types
        pattern_types = Counter()
        frequencies = []
        
        for pattern, data in patterns.items():
            pattern_types[data['pattern_type']] += 1
            frequencies.append(data['frequency'])
        
        print(f"ğŸ“ˆ Pattern types distribution:")
        for ptype, count in pattern_types.most_common():
            print(f"  {ptype}: {count} patterns")
        
        print(f"ğŸ“Š Frequency statistics:")
        print(f"  Average frequency: {sum(frequencies)/len(frequencies):.1f}")
        print(f"  Max frequency: {max(frequencies)}")
        print(f"  Min frequency: {min(frequencies)}")
        
        # Show top patterns
        print(f"\nğŸ† Top 10 discovered patterns:")
        sorted_patterns = sorted(patterns.items(), key=lambda x: x[1]['frequency'], reverse=True)
        for i, (pattern, data) in enumerate(sorted_patterns[:10], 1):
            print(f"  {i:2d}. {pattern}: {data['frequency']} occurrences ({data['pattern_type']})")
    
    # Analyze collocation data
    collocation_file = research_dir / "collocation_analysis_20251025_144617.json"
    if collocation_file.exists():
        print("\nğŸ“Š COLLOCATION ANALYSIS")
        print("-" * 40)
        
        with open(collocation_file, 'r', encoding='utf-8') as f:
            collocations = json.load(f)
        
        for measure, results in collocations.items():
            print(f"\nğŸ“ˆ {measure.upper()} Analysis:")
            print(f"  Total collocations: {len(results)}")
            
            if results:
                # Show top 5 for each measure
                print(f"  Top 5 collocations:")
                for i, result in enumerate(results[:5], 1):
                    words = ' '.join(result['words'])
                    print(f"    {i}. {words}: {result['score']:.3f} (freq: {result['frequency']})")
    
    # Analyze API responses
    api_file = research_dir / "api_responses_20251025_144617.json"
    if api_file.exists():
        print("\nğŸ¤– API RESPONSES ANALYSIS")
        print("-" * 40)
        
        with open(api_file, 'r', encoding='utf-8') as f:
            api_responses = json.load(f)
        
        print(f"ğŸ“Š Processed {len(api_responses)} API queries")
        
        for query_id, response in api_responses.items():
            query = response['query']
            query_type = response['data']['query_type']
            print(f"\nğŸ” Query: {query}")
            print(f"   Type: {query_type}")
            
            if 'gold_standard_patterns' in response['data']:
                print(f"   Gold standard patterns: {response['data']['gold_standard_patterns']}")
            if 'pattern_categories' in response['data']:
                print(f"   Pattern categories: {len(response['data']['pattern_categories'])}")
    
    # Analyze Bible data if available
    bible_analysis_file = research_dir / "bible_analysis_20251025_144618.json"
    if bible_analysis_file.exists():
        print("\nğŸ“– BIBLE DATA ANALYSIS")
        print("-" * 40)
        
        with open(bible_analysis_file, 'r', encoding='utf-8') as f:
            bible_data = json.load(f)
        
        print(f"ğŸ“š Bible corpus analyzed: {bible_data['metadata']['corpus_size']} sentences")
        print(f"ğŸ§  Knowledge sources: {bible_data['metadata']['knowledge_sources']}")
        
        # Show linguistic insights
        if 'linguistic_analysis' in bible_data:
            insights = bible_data['linguistic_analysis']
            print(f"ğŸ”¬ Linguistic insights generated: {len(insights)}")
            
            for insight_type, data in insights.items():
                if isinstance(data, dict):
                    print(f"  {insight_type}: {len(data)} items")
    
    # Analyze Bible collocations
    bible_collocation_file = research_dir / "bible_collocations_20251025_144618.json"
    if bible_collocation_file.exists():
        print("\nğŸ“Š BIBLE COLLOCATIONS ANALYSIS")
        print("-" * 40)
        
        with open(bible_collocation_file, 'r', encoding='utf-8') as f:
            bible_collocations = json.load(f)
        
        for measure, results in bible_collocations.items():
            print(f"\nğŸ“ˆ Bible {measure.upper()} Analysis:")
            print(f"  Total collocations: {len(results)}")
            
            if results:
                # Show top 5 for each measure
                print(f"  Top 5 Bible collocations:")
                for i, result in enumerate(results[:5], 1):
                    words = ' '.join(result['words'])
                    print(f"    {i}. {words}: {result['score']:.3f} (freq: {result['frequency']})")

def show_sample_data():
    """Show sample data from the research files"""
    
    print("\nğŸ“‹ SAMPLE DATA PREVIEW")
    print("=" * 60)
    
    # Show sample from discovered patterns
    patterns_file = Path("research/discovered_patterns_20251025_144617.json")
    if patterns_file.exists():
        print("\nğŸ” Sample Discovered Patterns:")
        with open(patterns_file, 'r', encoding='utf-8') as f:
            patterns = json.load(f)
        
        # Show first 5 patterns
        for i, (pattern, data) in enumerate(list(patterns.items())[:5], 1):
            print(f"  {i}. {pattern}")
            print(f"     Words: {data['words']}")
            print(f"     Frequency: {data['frequency']}")
            print(f"     Type: {data['pattern_type']}")
            print(f"     Confidence: {data['confidence']}")
            print()
    
    # Show sample from collocation analysis
    collocation_file = Path("research/collocation_analysis_20251025_144617.json")
    if collocation_file.exists():
        print("ğŸ“Š Sample Collocation Analysis:")
        with open(collocation_file, 'r', encoding='utf-8') as f:
            collocations = json.load(f)
        
        for measure, results in collocations.items():
            if results:
                print(f"\n  {measure.upper()} - Top 3:")
                for i, result in enumerate(results[:3], 1):
                    words = ' '.join(result['words'])
                    print(f"    {i}. {words}: {result['score']:.3f} (freq: {result['frequency']})")

def main():
    """Main analysis function"""
    print("ğŸ¯ K'CHO RESEARCH DATA ANALYZER")
    print("=" * 80)
    print("This script analyzes the comprehensive research data generated")
    print("by the enhanced KchoSystem with real K'Cho data.")
    print("=" * 80)
    
    try:
        analyze_research_data()
        show_sample_data()
        
        print("\nğŸ‰ ANALYSIS COMPLETE!")
        print("=" * 60)
        print("âœ… Comprehensive research data analyzed")
        print("âœ… Novel patterns discovered and categorized")
        print("âœ… Collocation analysis completed")
        print("âœ… API responses processed")
        print("âœ… Bible data analyzed")
        print("âœ… All data ready for LLaMA integration")
        
    except Exception as e:
        print(f"âŒ Error during analysis: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()


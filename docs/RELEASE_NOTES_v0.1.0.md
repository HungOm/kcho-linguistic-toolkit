# K'Cho Linguistic Toolkit v0.1.0 Release Notes

## ğŸ‰ First Official Release: K'Cho Linguistic Toolkit

This is the first official release of the K'Cho Linguistic Toolkit, a comprehensive Python package for linguistic analysis of the K'Cho language. Developed by Hung Om, an enthusiastic K'Cho speaker and independent developer, this toolkit provides essential tools for working with K'Cho, a Kuki-Chin language spoken by 10,000-20,000 people in southern Chin State, Myanmar.

## âœ¨ What's New

### ğŸ—ï¸ **Professional Python Package**
- **Clean Package Structure**: Organized into proper `kcho/` package following Python best practices
- **Easy Installation**: Install with `pip install -e .` for development or distribute via PyPI
- **Comprehensive Documentation**: Complete README, API docs, and usage examples
- **Professional .gitignore**: Excludes large files while keeping essential references

### ğŸš€ **Core Linguistic Analysis Features**
- **Collocation Extraction**: Multiple association measures (PMI, NPMI, t-score, Dice, Log-likelihood)
- **Morphological Analysis**: Analyze K'Cho word structure (stems, affixes, particles)
- **Text Normalization**: Clean and normalize K'Cho text for analysis
- **Corpus Building**: Create annotated datasets with quality control
- **Lexicon Management**: Build and manage digital K'Cho dictionaries
- **Data Export**: Export to standard formats (JSON, CoNLL-U, CSV)

### ğŸ”§ **Advanced defaultdict Functionality**
- **POS Pattern Analysis**: Group collocations by part-of-speech patterns
- **Word Context Analysis**: Analyze word co-occurrence with nested structures
- **Morphological Pattern Extraction**: Identify prefixes, suffixes, and combinations
- **Sentence Structure Analysis**: Analyze syntactic patterns and complexity
- **Efficient Data Grouping**: Automatic list/dict creation without manual initialization

### ğŸ“¦ **Package Data Organization**
- **Package Data**: Core linguistic knowledge base included in installation
- **External Data**: Large datasets organized separately (Bible translations, parallel corpora)
- **Sample Data**: Small reference files for testing and examples
- **Research Outputs**: Generated analysis results (not included in package)

## ğŸ”§ **Installation & Usage**

### Installation
```bash
# Clone the repository
git clone https://github.com/HungOmungom/kcho-linguistic-toolkit.git
cd kcho-linguistic-toolkit

# Install in development mode
pip install -e .

# Verify installation
python -c "from kcho import CollocationExtractor; print('âœ… Success!')"
```

### Basic Usage
```python
from kcho import CollocationExtractor, KchoSystem

# Initialize the system
system = KchoSystem()

# Extract collocations
extractor = CollocationExtractor()
corpus = ["Om noh Yong am paapai pe ci", "Ak'hmÃ³ lÃ¹um ci"]
results = extractor.extract(corpus)

# Use advanced defaultdict functionality
pos_patterns = system.corpus.analyze_pos_patterns()
word_contexts = extractor.analyze_word_contexts(corpus)
```

### Command Line Interface
```bash
# Extract collocations
python -m kcho.create_gold_standard --corpus data/sample_corpus.txt --output gold_standard.txt

# Run examples
python examples/defaultdict_usage.py
```

## ğŸ“ **Project Structure**

```
KchoLinguisticToolkit/
â”œâ”€â”€ kcho/                           # Main package
â”‚   â”œâ”€â”€ __init__.py                 # Package initialization
â”‚   â”œâ”€â”€ collocation.py              # Collocation extraction
â”‚   â”œâ”€â”€ kcho_system.py              # Core system
â”‚   â”œâ”€â”€ normalize.py                # Text normalization
â”‚   â”œâ”€â”€ evaluation.py               # Evaluation utilities
â”‚   â”œâ”€â”€ export.py                   # Export functions
â”‚   â”œâ”€â”€ eng_kcho_parallel_extractor.py
â”‚   â”œâ”€â”€ export_training_csv.py
â”‚   â”œâ”€â”€ create_gold_standard.py     # Gold standard helper
â”‚   â”œâ”€â”€ kcho_app.py                 # CLI entry point
â”‚   â””â”€â”€ data/                       # Package data
â”‚       â”œâ”€â”€ linguistic_data.json
â”‚       â””â”€â”€ word_frequency_top_1000.csv
â”œâ”€â”€ examples/                       # Example scripts
â”‚   â””â”€â”€ defaultdict_usage.py
â”œâ”€â”€ data/                           # External data (not in package)
â”‚   â”œâ”€â”€ README.md                   # Data documentation
â”‚   â”œâ”€â”€ sample_corpus.txt           # Small, keep in git
â”‚   â”œâ”€â”€ gold_standard_collocations.txt
â”‚   â”œâ”€â”€ bible_versions/             # Large, .gitignored
â”‚   â”œâ”€â”€ parallel_corpora/           # Medium, .gitignored
â”‚   â””â”€â”€ research_outputs/           # Generated, .gitignored
â”œâ”€â”€ .gitignore                      # Comprehensive ignore rules
â”œâ”€â”€ pyproject.toml                  # Package configuration
â”œâ”€â”€ LICENSE                         # MIT License
â””â”€â”€ README.md                       # Documentation
```

## ğŸ“Š **Data Organization**

### Package Data (included in installation)
- `kcho/data/linguistic_data.json` - Core linguistic knowledge base
- `kcho/data/word_frequency_top_1000.csv` - High-frequency word list

### External Data (not in package)
- `data/sample_corpus.txt` - Small sample corpus for testing
- `data/gold_standard_collocations.txt` - Gold standard annotations
- `data/bible_versions/` - Bible translations (public domain, large files)
- `data/parallel_corpora/` - Aligned parallel texts
- `data/research_outputs/` - Generated analysis results

**Note**: Large data files are not included in the package to keep it lightweight. See `data/README.md` for details.

## ğŸ§ª **Testing**

The package has been thoroughly tested:

```bash
# Test imports
python -c "from kcho import CollocationExtractor, KchoSystem; print('âœ… Imports work!')"

# Test CLI
python -m kcho.create_gold_standard --corpus data/sample_corpus.txt --output test.txt --auto

# Test examples
python examples/defaultdict_usage.py
```

## ğŸ“š **Documentation**

- **[README.md](README.md)** - Complete installation and usage guide
- **[GUIDE.md](GUIDE.md)** - Detailed user guide
- **[KCHO_TOOLKIT_DOCS.md](KCHO_TOOLKIT_DOCS.md)** - API documentation
- **[DEFAULTDICT_INTEGRATION.md](DEFAULTDICT_INTEGRATION.md)** - defaultdict functionality guide
- **[data/README.md](data/README.md)** - Data organization and copyright information

## ğŸ”¬ **Research Foundation**

This toolkit implements findings from:
- **Bedell, G. & Mang, K. S. (2012)**. "The Applicative Suffix -na in K'Cho"
- **Jordan, M. (1969)**. "Chin Dictionary and Grammar"
- **Mang, K. S. & Bedell, G. (2006)**. "Relative Clauses in K'Cho"

## ğŸ› ï¸ **Tools and Libraries Used**

This toolkit builds upon several excellent open-source tools:

- **Python Standard Library** - Core functionality
- **NLTK** - Natural language processing utilities
- **scikit-learn** - Machine learning algorithms
- **NumPy** - Numerical computing
- **Click** - Command-line interface framework
- **Python collections** - defaultdict and Counter for efficient data structures

## ğŸ¤ **Contributing**

We welcome contributions! Please see the documentation for:
- Code style guidelines
- Testing requirements
- Data contribution guidelines
- Issue reporting

## ğŸ“„ **License**

MIT License - see LICENSE file for details.

## ğŸ™ **Acknowledgments**

- **K'Cho language community** - For preserving and sharing the language
- **Linguistic researchers** - Bedell & Mang (2012) for foundational research
- **Open source community** - For the excellent tools and libraries
- **Public domain Bible translation providers** - For making translations available
- **Python community** - For the robust ecosystem and packaging tools

---

**Full Changelog**: This is the first official release of the K'Cho Linguistic Toolkit.

**Download**: [Source Code (zip)](https://github.com/HungOm/kcho-linguistic-toolkit/archive/refs/tags/v0.1.0.zip) | [Source Code (tar.gz)](https://github.com/hungom/kcho-linguistic-toolkit/archive/refs/tags/v0.1.0.tar.gz)
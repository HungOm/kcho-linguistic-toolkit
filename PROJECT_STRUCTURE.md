# Project Structure

**Author**: Hung Om  
**Research Foundation**: Based on foundational K'Cho linguistic research and Austroasiatic language studies  
**Version**: 0.2.0  
**Date**: 2025-01-25

## Abstract

This document describes the architecture and organization of the K'Cho Linguistic Processing Toolkit, a computational system for analyzing K'Cho language structure, morphology, and syntax using modern software engineering practices.

## Directory Organization

```
KChoCaToolKit/
â”œâ”€â”€ README.md                    # Main documentation
â”œâ”€â”€ LICENSE                      # MIT License
â”œâ”€â”€ pyproject.toml              # Package configuration
â”œâ”€â”€ MIGRATION_CLI_GUIDE.md       # Migration commands guide
â”‚
â”œâ”€â”€ kcho/                        # Main package
â”‚   â”œâ”€â”€ __init__.py             # Package exports
â”‚   â”œâ”€â”€ kcho_system.py          # Core system classes
â”‚   â”œâ”€â”€ knowledge_base.py        # SQLite backend
â”‚   â”œâ”€â”€ api_layer.py             # API integration layer
â”‚   â”œâ”€â”€ data_migration.py        # Data migration system
â”‚   â”œâ”€â”€ kcho_app.py             # CLI application
â”‚   â”œâ”€â”€ kcho_lexicon.db         # SQLite database
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                    # Package data
â”‚   â”‚   â”œâ”€â”€ linguistic_data.json
â”‚   â”‚   â”œâ”€â”€ gold_standard_collocations.txt
â”‚   â”‚   â”œâ”€â”€ word_frequency_top_1000.csv
â”‚   â”‚   â”œâ”€â”€ gold_standard_kcho_english.json
â”‚   â”‚   â””â”€â”€ sample_corpus.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ normalize.py             # Text normalization
â”‚   â”œâ”€â”€ collocation.py           # Collocation extraction
â”‚   â”œâ”€â”€ ngram_collocation.py     # N-gram analysis
â”‚   â”œâ”€â”€ evaluation.py            # Evaluation metrics
â”‚   â”œâ”€â”€ export.py                # Data export utilities
â”‚   â””â”€â”€ text_loader.py           # Text loading utilities
â”‚
â”œâ”€â”€ examples/                    # Usage examples
â”‚   â”œâ”€â”€ README.md               # Examples documentation
â”‚   â”œâ”€â”€ enhanced_kcho_system_demo.py
â”‚   â”œâ”€â”€ practical_demonstration.py
â”‚   â”œâ”€â”€ generate_research_data.py
â”‚   â””â”€â”€ tutorials/
â”‚       â”œâ”€â”€ collocation_extraction_tutorial.py
â”‚       â””â”€â”€ ngram_collocation_test.py
â”‚
â”œâ”€â”€ tests/                       # Test suite
â”‚   â”œâ”€â”€ test_knowledge_base.py   # Database tests
â”‚   â”œâ”€â”€ test_data_migration.py  # Migration tests
â”‚   â”œâ”€â”€ test_collocation.py     # Collocation tests
â”‚   â”œâ”€â”€ test_corpus.py          # Corpus tests
â”‚   â””â”€â”€ test_main_system.py     # System tests
â”‚
â”œâ”€â”€ docs/                        # Additional documentation
â”‚   â”œâ”€â”€ README.md               # Documentation index
â”‚   â”œâ”€â”€ COLLOCATION_GUIDE.md    # Collocation analysis guide
â”‚   â””â”€â”€ RELEASE_NOTES_v0.1.0.md # Release notes
â”‚
â”œâ”€â”€ data/                        # Research data
â”‚   â”œâ”€â”€ README.md               # Data documentation
â”‚   â”œâ”€â”€ bible_versions/         # Bible translations
â”‚   â””â”€â”€ parallel_corpora/       # Parallel texts
â”‚
â”œâ”€â”€ research/                    # Research outputs
â”‚   â”œâ”€â”€ cli_bible_analysis.csv
â”‚   â”œâ”€â”€ cli_sample_analysis.csv
â”‚   â””â”€â”€ cli_sample_ngrams.csv
â”‚
â””â”€â”€ venv/                       # Virtual environment
```

## ğŸ—ï¸ Architecture Overview

### Core Components

1. **Knowledge Base Layer** (`knowledge_base.py`)
   - SQLite database backend
   - Data migration and versioning
   - CRUD operations for linguistic data

2. **System Layer** (`kcho_system.py`)
   - Main orchestrator classes
   - Pattern discovery engines
   - Linguistic analysis components

3. **API Layer** (`api_layer.py`)
   - External integration interface
   - Query processing and response formatting
   - LLaMA integration support

4. **CLI Layer** (`kcho_app.py`)
   - Command-line interface
   - Migration management commands
   - Analysis and research tools

### Data Flow

```
Raw Text â†’ Normalization â†’ Tokenization â†’ Analysis â†’ Database Storage
    â†“
Pattern Discovery â†’ Research Engine â†’ API Layer â†’ External Systems
```

### Database Schema

- **verb_stems**: Verb morphology data
- **collocations**: Word co-occurrence patterns
- **word_frequencies**: Statistical frequency data
- **parallel_sentences**: Translation pairs
- **raw_texts**: Unprocessed text for discovery
- **word_categories**: Lexical categorization

## ğŸ”§ Development Guidelines

### Code Organization
- **Single Responsibility**: Each module has a clear purpose
- **Separation of Concerns**: Database, business logic, and API layers separated
- **Dependency Injection**: Components receive dependencies rather than creating them

### Naming Conventions
- **Classes**: PascalCase (e.g., `KchoKnowledge`, `PatternDiscoveryEngine`)
- **Functions**: snake_case (e.g., `get_verb_stem`, `discover_patterns`)
- **Constants**: UPPER_CASE (e.g., `VERB_STEMS`, `GOLD_STANDARD_PATTERNS`)

### Testing Strategy
- **Unit Tests**: Individual component testing
- **Integration Tests**: Cross-component functionality
- **Performance Tests**: Database query optimization
- **Compatibility Tests**: Backward compatibility verification

## ğŸ“¦ Package Structure

### Public API (`__init__.py`)
```python
# Core classes
from kcho import KchoKnowledge, KchoSystem
from kcho import PatternDiscoveryEngine, LinguisticResearchEngine
from kcho import KchoAPILayer

# Database utilities
from kcho import KchoKnowledgeBase, init_database

# Migration system
from kcho import DataMigrationManager, check_and_migrate_data
```

### Internal Modules
- **normalize.py**: Text preprocessing utilities
- **collocation.py**: Statistical collocation analysis
- **evaluation.py**: Performance metrics and evaluation
- **export.py**: Data export and serialization

## ğŸš€ Deployment

### Production Setup
1. Install dependencies: `pip install -e .`
2. Initialize database: `python -m kcho.kcho_app migrate init`
3. Verify installation: `python examples/enhanced_kcho_system_demo.py`

### Development Setup
1. Clone repository
2. Create virtual environment: `python -m venv venv`
3. Activate environment: `source venv/bin/activate`
4. Install in development mode: `pip install -e .[dev]`
5. Run tests: `pytest tests/`

## ğŸ“Š Performance Considerations

### Database Optimization
- **Indexes**: Created on frequently queried fields
- **Caching**: LRU cache for hot data paths
- **Batch Operations**: Efficient bulk inserts and updates

### Memory Management
- **Lazy Loading**: Data loaded on-demand
- **Connection Pooling**: Optimized database connections
- **Garbage Collection**: Proper resource cleanup

### Scalability
- **Modular Design**: Easy to extend with new components
- **Plugin Architecture**: Support for custom analyzers
- **API Layer**: Ready for distributed deployment
